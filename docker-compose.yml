# LocalAgent Multi-Provider LLM Orchestration Platform
# Production-ready deployment with Ollama, Redis, and monitoring

services:
  # Main LocalAgent CLI service
  localagent:
    build:
      context: .
      dockerfile: docker/Dockerfile
    image: localagent:latest
    container_name: localagent-cli
    environment:
      # Provider configurations
      - OLLAMA_BASE_URL=http://ollama:11434
      - REDIS_URL=redis://redis:6379/0
      
      # Security settings
      - LOCALAGENT_SECURE_KEYSTORE=true
      - LOCALAGENT_LOG_LEVEL=INFO
      
      # UnifiedWorkflow integration
      - UNIFIED_WORKFLOW_ENABLED=true
      - MCP_MEMORY_URL=redis://redis:6379/1
      - MCP_COORDINATION_URL=redis://redis:6379/2
      
      # Optional API keys (use secrets in production)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY:-}
      
    volumes:
      # Configuration and data persistence
      - localagent-config:/app/config
      - localagent-cache:/app/.cache
      - localagent-logs:/app/logs
      
      # Optional: mount local config for development
      # - ./config:/app/config:ro
      
    depends_on:
      ollama:
        condition: service_healthy
      redis:
        condition: service_healthy
        
    networks:
      - localagent-network
      
    restart: unless-stopped
    
    # Resource limits for production
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Ollama - Local LLM inference server
  ollama:
    image: ollama/ollama:latest
    container_name: localagent-ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_ORIGINS=*
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - localagent-network
    restart: unless-stopped
    
    # GPU support (uncomment if available)
    # runtime: nvidia
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all
    
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '1.0'
          memory: 2G

  # Redis - Memory and coordination backend
  redis:
    image: redis:7.2-alpine
    container_name: localagent-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - localagent-network
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # Optional: Prometheus monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: localagent-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - localagent-network
    restart: unless-stopped
    profiles:
      - monitoring

  # Optional: Grafana dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: localagent-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=localagent123
    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./config/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    networks:
      - localagent-network
    restart: unless-stopped
    profiles:
      - monitoring

volumes:
  # Persistent data volumes
  localagent-config:
    driver: local
  localagent-cache:
    driver: local
  localagent-logs:
    driver: local
  ollama-data:
    driver: local
  redis-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local

networks:
  localagent-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.22.0.0/16